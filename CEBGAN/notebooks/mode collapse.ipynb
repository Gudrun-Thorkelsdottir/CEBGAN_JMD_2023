{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.10 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Sinkhorn Algorithm and Sinkhorn Divergence"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch\r\n",
    "\r\n",
    "def lse(V):\r\n",
    "    v_m = torch.max(V, dim=1, keepdim=True).values\r\n",
    "    return v_m + (V - v_m).exp().sum(dim=1, keepdim=True).log()\r\n",
    "\r\n",
    "def sink_maps(x, y, eps, p):\r\n",
    "    C = torch.norm(x.unsqueeze(1) - y.unsqueeze(0), dim=2, p=p) / eps\r\n",
    "    S_f = lambda g: -lse(g.view(1, -1) - C)\r\n",
    "    S_g = lambda f: -lse(f.view(1, -1) - C.T)\r\n",
    "    return S_f, S_g\r\n",
    "\r\n",
    "def sink(a, x, b, y, p=2, eps=1, iter=100, tol=1e-3, converge=True):\r\n",
    "    a_log, b_log = a.log(), b.log()\r\n",
    "    f, g = torch.zeros_like(a), torch.zeros_like(b)\r\n",
    "    S_f, S_g = sink_maps(x, y, eps, p)\r\n",
    "    with torch.set_grad_enabled(not converge):\r\n",
    "        for i in range(iter):\r\n",
    "            g_old = g\r\n",
    "            f = S_f(g + b_log)\r\n",
    "            g = S_g(f + a_log)\r\n",
    "            if eps * (g - g_old).abs().mean() < tol: break\r\n",
    "    if not converge:\r\n",
    "        return eps * S_f(g + b_log), eps * S_g(f + a_log)\r\n",
    "    else:\r\n",
    "        S_f, _ = sink_maps(x.detach(), y, eps, p)\r\n",
    "        _, S_g = sink_maps(x, y.detach(), eps, p)\r\n",
    "        return eps * S_f((g + b_log).detach()), eps * S_g((f + a_log).detach())\r\n",
    "\r\n",
    "def entropic_ot(a, x, b, y, **kwargs):\r\n",
    "    f, g = sink(a, x, b, y, **kwargs)\r\n",
    "    return f.T @ a + g.T @ b\r\n",
    "\r\n",
    "def sinkhorn_divergence(a, x, b, y, **kwargs):\r\n",
    "    return entropic_ot(a, x, b, y, **kwargs) \\\r\n",
    "        - 0.5 * entropic_ot(a, x, a, x, **kwargs) \\\r\n",
    "        - 0.5 * entropic_ot(b, y, b, y, **kwargs)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# GAN Toy Problem\n",
    "## Gaussian Mixture Dataset"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from math import pi\r\n",
    "\r\n",
    "size = 100\r\n",
    "angles = torch.linspace(0, 7/4*pi, 8).view(-1, 1)\r\n",
    "shift = 15 * torch.hstack([torch.cos(angles), torch.sin(angles)]).repeat(size, 1)\r\n",
    "dataset = torch.randn(8*size, 2) + shift"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import matplotlib.pyplot as plt\r\n",
    "plt.scatter(dataset[:, 0], dataset[:, 1], s=3)\r\n",
    "plt.gca().set_aspect('equal', adjustable='box')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Vanilla GAN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import torch.nn as nn\r\n",
    "\r\n",
    "class Generator(nn.Module):\r\n",
    "    def __init__(self, in_features=2, width=100):\r\n",
    "        super().__init__()\r\n",
    "        self.model = nn.Sequential(\r\n",
    "            nn.Linear(in_features, width),\r\n",
    "            nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, width),\r\n",
    "            nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, width),\r\n",
    "            nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, width),\r\n",
    "            nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, width),\r\n",
    "            nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, 2)\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self, input):\r\n",
    "        return self.model(input)\r\n",
    "\r\n",
    "class Discriminator(nn.Module):\r\n",
    "    def __init__(self, in_features=2, width=100):\r\n",
    "        super().__init__()\r\n",
    "        self.model = nn.Sequential(\r\n",
    "            nn.Linear(in_features, width),\r\n",
    "            # nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, width),\r\n",
    "            # nn.BatchNorm1d(width),\r\n",
    "            nn.ReLU(),\r\n",
    "            nn.Linear(width, 1)\r\n",
    "        )\r\n",
    "    \r\n",
    "    def forward(self, input):\r\n",
    "        return self.model(input)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "import torch.nn.functional as F\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "epochs = 5000\r\n",
    "batch_size = 400\r\n",
    "latent_size = 2\r\n",
    "width = 1024\r\n",
    "\r\n",
    "# \r\n",
    "dataloader = DataLoader(\r\n",
    "    torch.tensor(dataset, device=device), \r\n",
    "    batch_size, shuffle=True\r\n",
    "    )\r\n",
    "\r\n",
    "discriminator = Discriminator(2, width).to(device)\r\n",
    "generator = Generator(latent_size, width).to(device)\r\n",
    "\r\n",
    "optimizer_D = torch.optim.Adam(discriminator.parameters(), 3e-4)\r\n",
    "optimizer_G = torch.optim.Adam(generator.parameters(), 3e-4)\r\n",
    "\r\n",
    "def js_loss_D(real, fake):\r\n",
    "    return F.binary_cross_entropy_with_logits(discriminator(real), torch.ones(len(real), 1, device=real.device)) \\\r\n",
    "        + F.binary_cross_entropy_with_logits(discriminator(fake), torch.zeros(len(fake), 1, device=fake.device))\r\n",
    "\r\n",
    "def js_loss_G(fake):\r\n",
    "    return - F.binary_cross_entropy_with_logits(discriminator(fake), torch.zeros(len(fake), 1, device=fake.device))\r\n",
    "    # return F.binary_cross_entropy_with_logits(discriminator(fake), torch.ones(len(fake), 1, device=fake.device))\r\n",
    "\r\n",
    "# record_epochs = [0, 10, 20, 30, 40, 50, 100, 200, 300, 400, 500, 600, 700, 800, 900, epochs-1]\r\n",
    "records = []\r\n",
    "\r\n",
    "for epoch in range(epochs):\r\n",
    "    for batch in dataloader:\r\n",
    "        for _ in range(5):\r\n",
    "            optimizer_D.zero_grad()\r\n",
    "            d_loss = js_loss_D(batch, generator(torch.rand(batch_size, latent_size, device=device)))\r\n",
    "            d_loss.backward()\r\n",
    "            optimizer_D.step()\r\n",
    "        for _ in range(1):\r\n",
    "            optimizer_G.zero_grad()\r\n",
    "            g_loss = js_loss_G(generator(torch.rand(batch_size, latent_size, device=device)))\r\n",
    "            g_loss.backward()\r\n",
    "            optimizer_G.step()\r\n",
    "\r\n",
    "    if epoch % 500 == 0 or epoch == epochs-1:\r\n",
    "        print('Epoch: {} \\t JS Loss: {:4f}'.format(epoch, d_loss.item()))\r\n",
    "    \r\n",
    "        record = generator(torch.rand(800, latent_size, device=device)).cpu().detach().numpy()\r\n",
    "        plt.scatter(dataset[:, 0], dataset[:, 1], s=3)\r\n",
    "        plt.scatter(record[:, 0], record[:, 1], s=3)\r\n",
    "        plt.xlim(-20, 20); plt.ylim(-20, 20)\r\n",
    "        plt.title('GAN')\r\n",
    "        plt.xlabel('x1')\r\n",
    "        plt.ylabel('x2')\r\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\r\n",
    "        plt.show()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## EGAN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "from torch.utils.data import DataLoader\r\n",
    "from torch.optim import Adam\r\n",
    "\r\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\r\n",
    "\r\n",
    "epochs = 5000 #10000\r\n",
    "batch_size = 400 #800\r\n",
    "latent_size = 2\r\n",
    "width = 1024\r\n",
    "\r\n",
    "dataloader = DataLoader(\r\n",
    "    torch.tensor(dataset, device=device), \r\n",
    "    batch_size, shuffle=True\r\n",
    "    )\r\n",
    "generator = Generator(latent_size, width).to(device)\r\n",
    "optimizer = Adam(generator.parameters(), lr=3e-4)\r\n",
    "\r\n",
    "record_epochs = [0, 10, 20, 30, 40, 50, 100, 300, 500, 1000, 5000, 9000, epochs-1]\r\n",
    "records = []\r\n",
    "\r\n",
    "for epoch in range(epochs):\r\n",
    "    for batch in dataloader:\r\n",
    "        optimizer.zero_grad()\r\n",
    "        loss = sinkhorn_divergence(\r\n",
    "            torch.ones(len(batch), 1, device=device) / len(batch), \r\n",
    "            batch, \r\n",
    "            torch.ones(batch_size, 1, device=device) / batch_size, \r\n",
    "            generator(torch.rand(batch_size, latent_size, device=device)),\r\n",
    "            eps=50 if epoch < 500 else 5e-4, iter=1000\r\n",
    "            )\r\n",
    "        loss.backward()\r\n",
    "        optimizer.step()\r\n",
    "\r\n",
    "    if epoch % 500 == 0 or epoch == epochs-1:\r\n",
    "        print('Epoch: {} \\t Sinkhorn Divergence: {:4f}'.format(epoch, loss.item()))\r\n",
    "\r\n",
    "        record = generator(torch.rand(800, latent_size, device=device)).cpu().detach().numpy()\r\n",
    "        plt.scatter(dataset[:, 0], dataset[:, 1], s=3)\r\n",
    "        plt.scatter(record[:, 0], record[:, 1], s=3)\r\n",
    "        plt.xlim(-20, 20); plt.ylim(-20, 20)\r\n",
    "        plt.title('Sinkhorn EGAN')\r\n",
    "        plt.xlabel('x1')\r\n",
    "        plt.ylabel('x2')\r\n",
    "        plt.gca().set_aspect('equal', adjustable='box')\r\n",
    "        plt.show()\r\n"
   ],
   "outputs": [],
   "metadata": {
    "tags": []
   }
  }
 ]
}